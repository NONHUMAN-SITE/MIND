# MIND  

![Main Image](imgs/main.png)  

**Welcome to MIND**, a repository designed to help you explore and understand the core components of Large Language Models (LLMs). Here, you will find diverse materials, including key research papers, architectures, in-depth conceptual explanations, and implementations.  

For additional notes and resources, visit: [www.nonhuman.site](http://www.nonhuman.site).  

---

## ðŸš€ Roadmap  

Below is the roadmap for this repository. Each topic is structured to guide your learning and includes a checklist to track progress:  

### 1. Fundamentals  
- [x] **1.1 Attention Is All You Need**  
- [x] **1.2 Implementation**  

### 2. Assistant  
- [ ] **2.1 Under development**  
- [ ] **2.2 RLHF**  
- [ ] **2.3 DPO**  

### 3. Optimization  
- [ ] **3.1 Under development**  
- [ ] **3.2 LoRA**  
- [ ] **3.3 Scaling Laws**  

### 4. Data  
- [ ] **4.1 Under development**  
- [ ] **4.2 Training Data and Benchmarks**  

### 5. Architectures  
- [ ] **5.1 Under development**  
- [ ] **5.2 MOE**  
- [ ] **5.3 VLM**  
- [ ] **5.4 Qwen2-Audio**  

### 6. Reasoning models  
- [ ] **6.1 Under development**  
- [ ] **6.2 Deepseek Math**  
- [ ] **6.3 Deepseek R1**  
- [ ] **6.4 Road to O1**  

### 7. Roadmap to O(1) (Test Time Compute)  
- [ ] **7.1 Optimization Techniques**  

---

## âœ… Updates  

### Current Progress  
We are currently working on:  
- **1.1 Attention Is All You Need**  

### Completed Tasks  
- Initial setup and structure  

---

Thank you for your interest in MIND! Feel free to contribute and share your insights as we continue to explore the fascinating world of Large Language Models.